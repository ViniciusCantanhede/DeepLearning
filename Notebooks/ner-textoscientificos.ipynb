{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-10T21:26:56.487168Z",
     "iopub.status.busy": "2024-12-10T21:26:56.486490Z",
     "iopub.status.idle": "2024-12-10T21:26:57.519268Z",
     "shell.execute_reply": "2024-12-10T21:26:57.518394Z",
     "shell.execute_reply.started": "2024-12-10T21:26:56.487120Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dl-2024/dadosTextosCientificos.tsv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:45:19.556871Z",
     "iopub.status.busy": "2024-12-10T22:45:19.556010Z",
     "iopub.status.idle": "2024-12-10T22:45:45.254639Z",
     "shell.execute_reply": "2024-12-10T22:45:45.253702Z",
     "shell.execute_reply.started": "2024-12-10T22:45:19.556835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.8.0/pt_core_news_lg-3.8.0-py3-none-any.whl (568.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.2/568.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pt-core-news-lg\n",
      "Successfully installed pt-core-news-lg-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extrair carateres especiais, espaços duplos, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:46:01.500050Z",
     "iopub.status.busy": "2024-12-10T22:46:01.499659Z",
     "iopub.status.idle": "2024-12-10T22:46:04.588500Z",
     "shell.execute_reply": "2024-12-10T22:46:04.587635Z",
     "shell.execute_reply.started": "2024-12-10T22:46:01.500016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando GPU: True\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# Configurar spaCy para usar GPU\n",
    "spacy.require_gpu()\n",
    "print(\"Usando GPU:\", spacy.prefer_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:46:07.901449Z",
     "iopub.status.busy": "2024-12-10T22:46:07.900943Z",
     "iopub.status.idle": "2024-12-10T22:46:07.964667Z",
     "shell.execute_reply": "2024-12-10T22:46:07.963817Z",
     "shell.execute_reply.started": "2024-12-10T22:46:07.901419Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Título_Público</th>\n",
       "      <th>Descricao_pública</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Açúcar de frutas e aplicação em bolos como sub...</td>\n",
       "      <td>O uso de inovações tecnológicas auxilia as ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desenvolver uma linha de farofas com castanhas...</td>\n",
       "      <td>O uso de inovações tecnológicas auxilia as ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desenvolvimento de cobertura líquida para sorvete</td>\n",
       "      <td>O Brasil é considerado um país com a maior bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desenvolvimento de conserva de tomate cereja</td>\n",
       "      <td>O Brasil é considerado o país com maior biodiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desenvolvimento de massa alimentícia enriqueci...</td>\n",
       "      <td>Nos últimos anos a comunidade científica tem d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>Desenvolvimento de ativos biotecnológicos para...</td>\n",
       "      <td>O avanço das tecnologias para estudos genômico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>SIMA MV POWER</td>\n",
       "      <td>Projeto de PD&amp;I para desenvolvimento de um sis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>Talhonameno Ótimo Klabin</td>\n",
       "      <td>A Klabin S/A é uma empresa brasileira, de cará...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>Tecnologia de Quantificação de Estoque de Carb...</td>\n",
       "      <td>Com a execução do presente projeto espera-se d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>Desenvolvimento de Plataforma Digital de Bioi...</td>\n",
       "      <td>Desenvolvimento de Plataforma Digital de Bioin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2725 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Título_Público  \\\n",
       "0     Açúcar de frutas e aplicação em bolos como sub...   \n",
       "1     Desenvolver uma linha de farofas com castanhas...   \n",
       "2     Desenvolvimento de cobertura líquida para sorvete   \n",
       "3          Desenvolvimento de conserva de tomate cereja   \n",
       "4     Desenvolvimento de massa alimentícia enriqueci...   \n",
       "...                                                 ...   \n",
       "2720  Desenvolvimento de ativos biotecnológicos para...   \n",
       "2721                                      SIMA MV POWER   \n",
       "2722                           Talhonameno Ótimo Klabin   \n",
       "2723  Tecnologia de Quantificação de Estoque de Carb...   \n",
       "2724  Desenvolvimento de Plataforma Digital de Bioi...   \n",
       "\n",
       "                                      Descricao_pública  \n",
       "0     O uso de inovações tecnológicas auxilia as ind...  \n",
       "1     O uso de inovações tecnológicas auxilia as ind...  \n",
       "2     O Brasil é considerado um país com a maior bio...  \n",
       "3     O Brasil é considerado o país com maior biodiv...  \n",
       "4     Nos últimos anos a comunidade científica tem d...  \n",
       "...                                                 ...  \n",
       "2720  O avanço das tecnologias para estudos genômico...  \n",
       "2721  Projeto de PD&I para desenvolvimento de um sis...  \n",
       "2722  A Klabin S/A é uma empresa brasileira, de cará...  \n",
       "2723  Com a execução do presente projeto espera-se d...  \n",
       "2724  Desenvolvimento de Plataforma Digital de Bioin...  \n",
       "\n",
       "[2725 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/dl-2024/dadosTextosCientificos.tsv',\n",
    "                   sep='\\t',\n",
    "                   engine='python',\n",
    "                   encoding='latin-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:46:35.705044Z",
     "iopub.status.busy": "2024-12-10T22:46:35.704682Z",
     "iopub.status.idle": "2024-12-10T22:46:38.638236Z",
     "shell.execute_reply": "2024-12-10T22:46:38.637500Z",
     "shell.execute_reply.started": "2024-12-10T22:46:35.705012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captando entidades de acordo com os temas: DUTOS, BIOATIVOS, BIOCOMBUSTÍVEIS e COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:46:57.740199Z",
     "iopub.status.busy": "2024-12-10T22:46:57.739819Z",
     "iopub.status.idle": "2024-12-10T22:46:57.752177Z",
     "shell.execute_reply": "2024-12-10T22:46:57.751304Z",
     "shell.execute_reply.started": "2024-12-10T22:46:57.740164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_train = [\n",
    "    (\"Desenvolvimento de formulação cosmética veiculando sistema nanoestruturado lipídico contendo pré-bioticos e pós-bióticos\", {\"entities\": [(93, 105, \"BIOATIVOS\"), (108, 120, \"BIOATIVOS\")]}),\n",
    "    (\"intuito de incrementar nutricionalmente esses alimentos, agregando compostos bioativos e fibras\",{\"entities\": [(77, 86, \"BIOATIVOS\")]}),\n",
    "    (\"A empresa BIOATIVOSGROUP celebra em parceria com a Unidade Embrapii da UFABC\",{\"entities\": [(10, 24, \"BIOATIVOS\")]}),\n",
    "    (\"macrofungos associado ao biofertilizante Acrescent® capazes de controlar fungos\", {\"entities\": [(25, 40, \"BIOATIVOS\")]}),\n",
    "    (\"podem ser recuperados e transformados em coprodutos de valores nutricionais e bioativos\", {\"entities\": [(78, 87, \"BIOATIVOS\")]}),\n",
    "    (\"farinha de Ora-Pro-Nobis visando conservação de compostos bioativos\", {\"entities\": [(11, 24, \"BIOATIVOS\")]}),\n",
    "    (\"Extração e caracterização de compostos bioativos\", {\"entities\": [(29, 48, \"BIOATIVOS\")]}),\n",
    "    (\"O objetivo do projeto é desenvolver Metodologia de Inspeção Baseada em Risco (IBR) para Sistemas de Dutos Flexíveis para a um planejamento do escopo de inspeção\", {\"entities\": [(100, 115, \"DUTOS\")]}),\n",
    "    (\"Dispositivo Mitigador de Vibração Induzida por Vórtice para Dutos Submarinos\", {\"entities\": [(60, 76, \"DUTOS\")]}),\n",
    "    (\"Integridade e extensão de vida de dutos flexíveis\", {\"entities\": [(34, 49, \"DUTOS\")]}),\n",
    "    (\"sensores de ondas guiadas que possa mapear com precisão adequada a corrosão em áreas críticas de dutos em operação\", {\"entities\": [(96, 101, \"DUTOS\")]}),\n",
    "    (\"Desenvolvimento de Metodologia para avaliação em Fadiga das amraduras de tração em Risers Flexíveis\", {\"entities\": [(83, 99, \"DUTOS\")]}),\n",
    "    (\"mecanismos de degradação causados pelos fenômenos de fadiga e corrosão fadiga em risers rígidos e flexíveis\", {\"entities\": [(81, 107, \"DUTOS\")]}),\n",
    "    (\"Desenvolvimento de tubos bimetálicos\", {\"entities\": [(19, 36, \"DUTOS\")]}),\n",
    "    (\"O objetivo geral do projeto é quantificar o efeito do liner na resistência ao colapso de dutos submarinos mecanicamente cladeados\", {\"entities\": [(89, 105, \"DUTOS\")]}),\n",
    "    (\"Inspeção de tubulações com reparos em compósito com técnica MWM-Array\", {\"entities\": [(12, 22, \"DUTOS\")]}),\n",
    "    (\"propriedades mecânicas e integridade estrutural sob hidrogenação em ligas de níquel com altos teores\", {\"entities\": [(69, 84, \"DUTOS\")]}),\n",
    "    (\"associado ao ambiente corrosivo demanda dutos de elevada espessura\", {\"entities\": [(40, 45, \"DUTOS\")]}),\n",
    "    (\"vibração induzida por vórtice que será acoplado a dutos submarinos\", {\"entities\": [(50, 66, \"DUTOS\")]}),\n",
    "    (\"Desenvolver em escala de laboratório (TRL 3) o conceito para formulação de biocombustível naval.\", {\"entities\": [(76, 90, \"BIOCOMBUSTÍVEIS\")]}),\n",
    "    (\"geração de açúcares avançados e a produção de biocombustíveis\", {\"entities\": [(45, 60, \"BIOCOMBUSTÍVEIS\")]}),\n",
    "    (\"Estratégias Enzimáticas para Biocombustiveis avançados\", {\"entities\": [(29, 44, \"BIOCOMBUSTÍVEIS\")]}),\n",
    "    (\"Desenvolvimento do processo de produção de combustíveis sustentáveis\", {\"entities\": [(43, 68, \"BIOCOMBUSTÍVEIS\")]}),\n",
    "    (\"Desenvolvimento de me?todos para produc?a?o de bioquerosene\", {\"entities\": [(47, 59, \"BIOCOMBUSTÍVEIS\")]}),\n",
    "    (\"Desenvolvimento de uma rota tecnológica para a produção de bio-óleo pirolenhoso\", {\"entities\": [(59, 67, \"BIOCOMBUSTÍVEIS\")]}),\n",
    "    (\"Candidatos a fármacos alvo dirigidos para o tratamento de infecções virais por Coronavírus\", {\"entities\": [(78, 89, \"COVID-19\")]}),\n",
    "    (\"Produção de proteína S de SARS-COV-2 para desenvolvimento de testes de diagnóstico sorológico.\", {\"entities\": [(26, 36, \"COVID-19\")]}),\n",
    "    (\"Sistema de Triagem inteligente para diagnóstico da Covid 19\", {\"entities\": [(51, 59, \"COVID-19\")]}),\n",
    "    (\"Avaliar o potencial de difusão da COVID-19 pelo sistema de esgoto em centros urbanos\", {\"entities\": [(34, 42, \"COVID-19\")]}),\n",
    "    (\"Desenvolver um método padronizado e otimizado para detecção do vírus SARS-CoV2 em amostras de efluentes\", {\"entities\": [(68, 77, \"COVID-19\")]}),\n",
    "    (\"O aumento da temperatura corporal é um dos indicadores para o diagnóstico de COVID19\", {\"entities\": [(77, 84, \"COVID-19\")]}),\n",
    "    (\"desenvolvendo um kit de teste quantitativo para monitoramento da COVID\", {\"entities\": [(65, 70, \"COVID-19\")]}),\n",
    "    (\"triagem e tratamento do covid 19 com uso de inteligência artificial\", {\"entities\": [(24, 32, \"COVID-19\")]}),\n",
    "    (\"Desenvolvimento de projeto de instrumentação e automação para sistema de higienização e sanitização de gases do Aerador-Filtro Anti-COVID\", {\"entities\": [(112, 137, \"COVID-19\")]})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento para reconhecer as entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:54:58.287701Z",
     "iopub.status.busy": "2024-12-10T22:54:58.287343Z",
     "iopub.status.idle": "2024-12-10T22:55:25.071238Z",
     "shell.execute_reply": "2024-12-10T22:55:25.070319Z",
     "shell.execute_reply.started": "2024-12-10T22:54:58.287671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-10 22:54:58,374] [INFO] Created vocabulary\n",
      "[2024-12-10 22:54:58,375] [INFO] Finished initializing nlp object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 Losses: {'ner': 340.02318942919374}\n",
      "Iteration 1 Losses: {'ner': 105.15050974596033}\n",
      "Iteration 2 Losses: {'ner': 56.061860582915585}\n",
      "Iteration 3 Losses: {'ner': 50.20962831809413}\n",
      "Iteration 4 Losses: {'ner': 45.41712229658356}\n",
      "Iteration 5 Losses: {'ner': 39.233577073310585}\n",
      "Iteration 6 Losses: {'ner': 39.850412801348895}\n",
      "Iteration 7 Losses: {'ner': 41.35663118632958}\n",
      "Iteration 8 Losses: {'ner': 47.70563071272673}\n",
      "Iteration 9 Losses: {'ner': 34.021011125986355}\n",
      "Iteration 10 Losses: {'ner': 29.573873683800528}\n",
      "Iteration 11 Losses: {'ner': 27.138512237150497}\n",
      "Iteration 12 Losses: {'ner': 23.42751169325361}\n",
      "Iteration 13 Losses: {'ner': 26.323659704035656}\n",
      "Iteration 14 Losses: {'ner': 14.816519659021232}\n",
      "Iteration 15 Losses: {'ner': 19.41776803421229}\n",
      "Iteration 16 Losses: {'ner': 11.670568890795323}\n",
      "Iteration 17 Losses: {'ner': 14.008300000391813}\n",
      "Iteration 18 Losses: {'ner': 12.711783663130415}\n",
      "Iteration 19 Losses: {'ner': 11.678893031066016}\n",
      "Iteration 20 Losses: {'ner': 10.567427317037366}\n",
      "Iteration 21 Losses: {'ner': 8.719005129850554}\n",
      "Iteration 22 Losses: {'ner': 11.366974690100955}\n",
      "Iteration 23 Losses: {'ner': 8.086432762822886}\n",
      "Iteration 24 Losses: {'ner': 7.515307469208864}\n",
      "Iteration 25 Losses: {'ner': 8.602369474944489}\n",
      "Iteration 26 Losses: {'ner': 9.080788861509278}\n",
      "Iteration 27 Losses: {'ner': 6.0235027546328785}\n",
      "Iteration 28 Losses: {'ner': 7.472565856800082}\n",
      "Iteration 29 Losses: {'ner': 7.9463902106304936}\n",
      "Iteration 30 Losses: {'ner': 7.006338299065311}\n",
      "Iteration 31 Losses: {'ner': 8.109711826390724}\n",
      "Iteration 32 Losses: {'ner': 3.2793729867128225}\n",
      "Iteration 33 Losses: {'ner': 6.7436864106048}\n",
      "Iteration 34 Losses: {'ner': 8.87096833644811}\n",
      "Iteration 35 Losses: {'ner': 4.26119703276998}\n",
      "Iteration 36 Losses: {'ner': 2.360647835443656}\n",
      "Iteration 37 Losses: {'ner': 3.4593763915483513}\n",
      "Iteration 38 Losses: {'ner': 2.028330100991832}\n",
      "Iteration 39 Losses: {'ner': 5.274568995724961}\n",
      "Iteration 40 Losses: {'ner': 1.5848794847598975}\n",
      "Iteration 41 Losses: {'ner': 3.3873980773686134}\n",
      "Iteration 42 Losses: {'ner': 4.385561039563745}\n",
      "Iteration 43 Losses: {'ner': 3.406097124464877}\n",
      "Iteration 44 Losses: {'ner': 4.8034418287026}\n",
      "Iteration 45 Losses: {'ner': 3.7572706330494747}\n",
      "Iteration 46 Losses: {'ner': 1.7799904146149617}\n",
      "Iteration 47 Losses: {'ner': 5.475974263055212}\n",
      "Iteration 48 Losses: {'ner': 1.9741752234386443}\n",
      "Iteration 49 Losses: {'ner': 4.059061041972956}\n",
      "Iteration 50 Losses: {'ner': 1.7426170009211754}\n",
      "Iteration 51 Losses: {'ner': 2.7546995057741666}\n",
      "Iteration 52 Losses: {'ner': 1.5961198342580472}\n",
      "Iteration 53 Losses: {'ner': 1.7163745538539932}\n",
      "Iteration 54 Losses: {'ner': 1.8295478929764095}\n",
      "Iteration 55 Losses: {'ner': 3.6485528421554956}\n",
      "Iteration 56 Losses: {'ner': 1.4524148595910722}\n",
      "Iteration 57 Losses: {'ner': 1.1594041035136768}\n",
      "Iteration 58 Losses: {'ner': 0.8137667334104528}\n",
      "Iteration 59 Losses: {'ner': 0.08817583796374882}\n",
      "Iteration 60 Losses: {'ner': 1.8924359361263932}\n",
      "Iteration 61 Losses: {'ner': 1.736469659278819}\n",
      "Iteration 62 Losses: {'ner': 2.2109687297704124}\n",
      "Iteration 63 Losses: {'ner': 0.34235754751968506}\n",
      "Iteration 64 Losses: {'ner': 1.5587535542837159}\n",
      "Iteration 65 Losses: {'ner': 1.9908329815221477}\n",
      "Iteration 66 Losses: {'ner': 0.17903663783482401}\n",
      "Iteration 67 Losses: {'ner': 0.06334968159780155}\n",
      "Iteration 68 Losses: {'ner': 0.9105209638957766}\n",
      "Iteration 69 Losses: {'ner': 0.2271659360076825}\n",
      "Iteration 70 Losses: {'ner': 2.163337192098158}\n",
      "Iteration 71 Losses: {'ner': 0.000830893031994215}\n",
      "Early stopping at iteration 71\n"
     ]
    }
   ],
   "source": [
    "#modelo spaCy vazio para português\n",
    "nlp = spacy.blank(\"pt\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# rótulos \n",
    "for _, annotations in data_train:\n",
    "    for ent in annotations[\"entities\"]:\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# Inicializar o otimizador\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "# Número máximo de iterações\n",
    "MAX_ITERATIONS = 100\n",
    "EARLY_STOPPING_THRESHOLD = 0.01  # Valor da loss para interrupção antecipada\n",
    "\n",
    "# Treinamento\n",
    "for iteration in range(MAX_ITERATIONS):\n",
    "    random.shuffle(data_train)  # Embaralhar os dados\n",
    "    losses = {}\n",
    "\n",
    "    # Criar batches para treinamento\n",
    "    batches = minibatch(data_train, size=compounding(4.0, 32.0, 1.001))\n",
    "\n",
    "    for batch in batches:\n",
    "        examples = []\n",
    "        for text, annotations in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            try:\n",
    "                example = Example.from_dict(doc, annotations)  # Verificar desalinhamento\n",
    "                examples.append(example)\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping misaligned entities in: '{text}' - {e}\")\n",
    "\n",
    "        # Atualizar o modelo\n",
    "        nlp.update(examples, sgd=optimizer, drop=0.35, losses=losses)\n",
    "\n",
    "    print(f\"Iteration {iteration} Losses: {losses}\")\n",
    "\n",
    "    # Verificar interrupção antecipada\n",
    "    if losses.get(\"ner\", 0) < EARLY_STOPPING_THRESHOLD:\n",
    "        print(f\"Early stopping at iteration {iteration}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:55:44.934900Z",
     "iopub.status.busy": "2024-12-10T22:55:44.934227Z",
     "iopub.status.idle": "2024-12-10T22:55:44.989670Z",
     "shell.execute_reply": "2024-12-10T22:55:44.988861Z",
     "shell.execute_reply.started": "2024-12-10T22:55:44.934868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo NER salvo.\n"
     ]
    }
   ],
   "source": [
    "# Salve o modelo\n",
    "nlp.to_disk(\"costum_ner\")\n",
    "print(\"Modelo NER salvo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando modelo NER personalizado para as entidades criadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T23:23:48.871338Z",
     "iopub.status.busy": "2024-12-10T23:23:48.870624Z",
     "iopub.status.idle": "2024-12-10T23:23:49.025828Z",
     "shell.execute_reply": "2024-12-10T23:23:49.024959Z",
     "shell.execute_reply.started": "2024-12-10T23:23:48.871303Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: O projeto tem como objetivo otimizar e escalonar a tecnologia de produção da proteína S do coronavírus SARS-COV-2, para que as empresas parceiras desenvolvam testes para diagnóstico sorológico de COVID-19, assim como estabelecer um painel de soros/plasmas positivos e negativos para COVID-19, que permita validar os testes diagnóstico e registrá-los junto à ANVISA\n",
      "Entidades: [('SARS-COV-2', 'COVID-19'), ('COVID-19', 'COVID-19'), ('COVID-19', 'COVID-19'), ('ANVISA', 'BIOATIVOS')]\n",
      "\n",
      "Texto: Desenvolvimento de me?todos para produc?a?o de bioquerosene/hidrocarbonetos verdes\n",
      "Entidades: [('bioquerosene', 'BIOCOMBUSTÍVEIS')]\n",
      "\n",
      "Texto: Estabelecer uma metodologia consistente para avaliação do fenômeno de fadiga desenvolvido nos arames que constituem as armaduras de tração de dutos flexíveis\n",
      "Entidades: [('dutos flexíveis', 'DUTOS')]\n",
      "\n",
      "Texto: Desenvolvimento de formulação cosmética veiculando sistema nanoestruturado lipídico contendo pré e pós-bióticos (vitaminas e ácidos graxos de cadeia curta) a fim de promoverem o equilíbrio da microbiota da pele\n",
      "Entidades: [('pós-bióticos', 'BIOATIVOS')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregue o modelo treinado\n",
    "nlp = spacy.load(\"costum_ner\")\n",
    "\n",
    "# Exemplo de textos para extração de entidades\n",
    "texts = [\n",
    "    \"O projeto tem como objetivo otimizar e escalonar a tecnologia de produção da proteína S do coronavírus SARS-COV-2, para que as empresas parceiras desenvolvam testes para diagnóstico sorológico de COVID-19, assim como estabelecer um painel de soros/plasmas positivos e negativos para COVID-19, que permita validar os testes diagnóstico e registrá-los junto à ANVISA\",\n",
    "    \"Desenvolvimento de me?todos para produc?a?o de bioquerosene/hidrocarbonetos verdes\",\n",
    "    \"Estabelecer uma metodologia consistente para avaliação do fenômeno de fadiga desenvolvido nos arames que constituem as armaduras de tração de dutos flexíveis\",\n",
    "    \"Desenvolvimento de formulação cosmética veiculando sistema nanoestruturado lipídico contendo pré e pós-bióticos (vitaminas e ácidos graxos de cadeia curta) a fim de promoverem o equilíbrio da microbiota da pele\"\n",
    "]\n",
    "\n",
    "# Extração de entidades\n",
    "entity_data = []\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    print(f\"Texto: {text}\\nEntidades: {entities}\\n\")\n",
    "    entity_data.append((text, entities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T23:25:18.214299Z",
     "iopub.status.busy": "2024-12-10T23:25:18.213323Z",
     "iopub.status.idle": "2024-12-10T23:25:18.231039Z",
     "shell.execute_reply": "2024-12-10T23:25:18.229893Z",
     "shell.execute_reply.started": "2024-12-10T23:25:18.214248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidade: compostos bioativos, Rótulo: BIOATIVOS\n",
      "Entidade: dutos submarinos, Rótulo: DUTOS\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Desenvolvimento de compostos bioativos e dutos submarinos.\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entidade: {ent.text}, Rótulo: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T23:34:27.890685Z",
     "iopub.status.busy": "2024-12-10T23:34:27.890330Z",
     "iopub.status.idle": "2024-12-10T23:34:27.895009Z",
     "shell.execute_reply": "2024-12-10T23:34:27.894049Z",
     "shell.execute_reply.started": "2024-12-10T23:34:27.890656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriquecendo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:05:46.802036Z",
     "iopub.status.busy": "2024-12-11T00:05:46.801299Z",
     "iopub.status.idle": "2024-12-11T00:06:05.493259Z",
     "shell.execute_reply": "2024-12-11T00:06:05.492538Z",
     "shell.execute_reply.started": "2024-12-11T00:05:46.801974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Carregar o modelo NER treinado\n",
    "nlp = spacy.load(\"costum_ner\")\n",
    "\n",
    "# Função para enriquecer textos com entidades extraídas\n",
    "def enrich_with_entities(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):  # Tratar valores nulos e tipos inesperados\n",
    "        return text\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    return text + \" \" + \" \".join(entities)  # Concatenar texto original com entidades\n",
    "\n",
    "# Aplicar a função para enriquecer os textos\n",
    "df[\"enriched_text\"] = df[\"Descricao_pública\"].apply(enrich_with_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:06:42.220897Z",
     "iopub.status.busy": "2024-12-11T00:06:42.220569Z",
     "iopub.status.idle": "2024-12-11T00:06:42.231782Z",
     "shell.execute_reply": "2024-12-11T00:06:42.230862Z",
     "shell.execute_reply.started": "2024-12-11T00:06:42.220870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Título_Público</th>\n",
       "      <th>Descricao_pública</th>\n",
       "      <th>enriched_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Açúcar de frutas e aplicação em bolos como sub...</td>\n",
       "      <td>O uso de inovações tecnológicas auxilia as ind...</td>\n",
       "      <td>O uso de inovações tecnológicas auxilia as ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desenvolver uma linha de farofas com castanhas...</td>\n",
       "      <td>O uso de inovações tecnológicas auxilia as ind...</td>\n",
       "      <td>O uso de inovações tecnológicas auxilia as ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desenvolvimento de cobertura líquida para sorvete</td>\n",
       "      <td>O Brasil é considerado um país com a maior bio...</td>\n",
       "      <td>O Brasil é considerado um país com a maior bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desenvolvimento de conserva de tomate cereja</td>\n",
       "      <td>O Brasil é considerado o país com maior biodiv...</td>\n",
       "      <td>O Brasil é considerado o país com maior biodiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desenvolvimento de massa alimentícia enriqueci...</td>\n",
       "      <td>Nos últimos anos a comunidade científica tem d...</td>\n",
       "      <td>Nos últimos anos a comunidade científica tem d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>Desenvolvimento de ativos biotecnológicos para...</td>\n",
       "      <td>O avanço das tecnologias para estudos genômico...</td>\n",
       "      <td>O avanço das tecnologias para estudos genômico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>SIMA MV POWER</td>\n",
       "      <td>Projeto de PD&amp;I para desenvolvimento de um sis...</td>\n",
       "      <td>Projeto de PD&amp;I para desenvolvimento de um sis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>Talhonameno Ótimo Klabin</td>\n",
       "      <td>A Klabin S/A é uma empresa brasileira, de cará...</td>\n",
       "      <td>A Klabin S/A é uma empresa brasileira, de cará...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>Tecnologia de Quantificação de Estoque de Carb...</td>\n",
       "      <td>Com a execução do presente projeto espera-se d...</td>\n",
       "      <td>Com a execução do presente projeto espera-se d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>Desenvolvimento de Plataforma Digital de Bioi...</td>\n",
       "      <td>Desenvolvimento de Plataforma Digital de Bioin...</td>\n",
       "      <td>Desenvolvimento de Plataforma Digital de Bioin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2725 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Título_Público  \\\n",
       "0     Açúcar de frutas e aplicação em bolos como sub...   \n",
       "1     Desenvolver uma linha de farofas com castanhas...   \n",
       "2     Desenvolvimento de cobertura líquida para sorvete   \n",
       "3          Desenvolvimento de conserva de tomate cereja   \n",
       "4     Desenvolvimento de massa alimentícia enriqueci...   \n",
       "...                                                 ...   \n",
       "2720  Desenvolvimento de ativos biotecnológicos para...   \n",
       "2721                                      SIMA MV POWER   \n",
       "2722                           Talhonameno Ótimo Klabin   \n",
       "2723  Tecnologia de Quantificação de Estoque de Carb...   \n",
       "2724  Desenvolvimento de Plataforma Digital de Bioi...   \n",
       "\n",
       "                                      Descricao_pública  \\\n",
       "0     O uso de inovações tecnológicas auxilia as ind...   \n",
       "1     O uso de inovações tecnológicas auxilia as ind...   \n",
       "2     O Brasil é considerado um país com a maior bio...   \n",
       "3     O Brasil é considerado o país com maior biodiv...   \n",
       "4     Nos últimos anos a comunidade científica tem d...   \n",
       "...                                                 ...   \n",
       "2720  O avanço das tecnologias para estudos genômico...   \n",
       "2721  Projeto de PD&I para desenvolvimento de um sis...   \n",
       "2722  A Klabin S/A é uma empresa brasileira, de cará...   \n",
       "2723  Com a execução do presente projeto espera-se d...   \n",
       "2724  Desenvolvimento de Plataforma Digital de Bioin...   \n",
       "\n",
       "                                          enriched_text  \n",
       "0     O uso de inovações tecnológicas auxilia as ind...  \n",
       "1     O uso de inovações tecnológicas auxilia as ind...  \n",
       "2     O Brasil é considerado um país com a maior bio...  \n",
       "3     O Brasil é considerado o país com maior biodiv...  \n",
       "4     Nos últimos anos a comunidade científica tem d...  \n",
       "...                                                 ...  \n",
       "2720  O avanço das tecnologias para estudos genômico...  \n",
       "2721  Projeto de PD&I para desenvolvimento de um sis...  \n",
       "2722  A Klabin S/A é uma empresa brasileira, de cará...  \n",
       "2723  Com a execução do presente projeto espera-se d...  \n",
       "2724  Desenvolvimento de Plataforma Digital de Bioin...  \n",
       "\n",
       "[2725 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando labels de acordo com os assuntos escolhidos e treinando classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:09:13.880865Z",
     "iopub.status.busy": "2024-12-11T00:09:13.880480Z",
     "iopub.status.idle": "2024-12-11T00:09:26.787479Z",
     "shell.execute_reply": "2024-12-11T00:09:26.786537Z",
     "shell.execute_reply.started": "2024-12-11T00:09:13.880835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696a7fe538e5411ca14fd3bada1c8121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26a32ab67bf40d1a7366dd5d465e92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_23/2740910689.py:93: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.302347</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.279306</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.277607</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de avaliação: {'eval_loss': 1.277606725692749, 'eval_accuracy': 0.5, 'eval_precision': 0.25, 'eval_recall': 0.5, 'eval_f1': 0.3333333333333333, 'eval_runtime': 0.0704, 'eval_samples_per_second': 28.408, 'eval_steps_per_second': 14.204, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import spacy\n",
    "\n",
    "# Configurações gerais\n",
    "MODEL_NAME = \"neuralmind/bert-base-portuguese-cased\"  # Modelo BERTimbau\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 3\n",
    "MAX_LEN = 128\n",
    "\n",
    "# Verificar se GPU está disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Carregar o modelo NER\n",
    "nlp = spacy.load(\"costum_ner\")\n",
    "\n",
    "# Função para enriquecer textos com entidades extraídas\n",
    "def enrich_with_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    return text + \" \" + \" \".join(entities)\n",
    "\n",
    "# Dados de exemplo (substituir por dados reais)\n",
    "data = {\n",
    "    \"train\": [\n",
    "        {\"text\": \"Os dutos submarinos precisam de manutenção urgente.\", \"label\": 0},\n",
    "        {\"text\": \"Biocombustíveis são o futuro da energia sustentável.\", \"label\": 1},\n",
    "        {\"text\": \"Os bioativos estão sendo usados em novas formulações cosméticas.\", \"label\": 2},\n",
    "        {\"text\": \"A pandemia de COVID-19 impactou a economia global.\", \"label\": 3},\n",
    "    ],\n",
    "    \"validation\": [\n",
    "        {\"text\": \"Dutos flexíveis são utilizados em ambientes corrosivos.\", \"label\": 0},\n",
    "        {\"text\": \"A extração de bioativos ajuda na saúde.\", \"label\": 2},\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Enriquecer os textos com entidades\n",
    "for split in data:\n",
    "    for item in data[split]:\n",
    "        item[\"text\"] = enrich_with_entities(item[\"text\"])\n",
    "\n",
    "# Convertendo os dados para DatasetDict\n",
    "train_dataset = Dataset.from_list(data[\"train\"])\n",
    "validation_dataset = Dataset.from_list(data[\"validation\"])\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"validation\": validation_dataset})\n",
    "\n",
    "# Carregando o tokenizer do modelo BERTimbau\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Função para tokenizar os textos\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "# Tokenizando os datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Configurar colunas para treinamento\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Carregando o modelo pré-treinado com número de classes definido\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=4)  # 4 classes\n",
    "model.to(device)  # Move o modelo explicitamente para a GPU\n",
    "\n",
    "# Configurar os argumentos de treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Função para calcular métricas de avaliação\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Configurar o Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "trainer.train()\n",
    "\n",
    "# Avaliação final\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Métricas de avaliação:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:09:36.802733Z",
     "iopub.status.busy": "2024-12-11T00:09:36.802368Z",
     "iopub.status.idle": "2024-12-11T00:09:36.882092Z",
     "shell.execute_reply": "2024-12-11T00:09:36.881032Z",
     "shell.execute_reply.started": "2024-12-11T00:09:36.802701Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textos: ['Os bioativos estão em alta na indústria farmacêutica.', 'Dutos rígidos são amplamente utilizados em engenharia offshore.', 'A pandemia de COVID-19 levou ao desenvolvimento de vacinas.', 'Biocombustíveis reduzem a emissão de carbono.']\n",
      "Predições: [2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predição em novos textos\n",
    "new_texts = [\n",
    "    \"Os bioativos estão em alta na indústria farmacêutica.\",\n",
    "    \"Dutos rígidos são amplamente utilizados em engenharia offshore.\",\n",
    "    \"A pandemia de COVID-19 levou ao desenvolvimento de vacinas.\",\n",
    "    \"Biocombustíveis reduzem a emissão de carbono.\"\n",
    "]\n",
    "\n",
    "# Enriquecer os novos textos com entidades\n",
    "new_texts_enriched = [enrich_with_entities(text) for text in new_texts]\n",
    "\n",
    "# Tokenizar os textos\n",
    "new_encodings = tokenizer(new_texts_enriched, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "new_encodings = {key: val.to(device) for key, val in new_encodings.items()}  # Move as entradas para GPU\n",
    "\n",
    "# Modelo em modo de avaliação\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**new_encodings)\n",
    "    predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "print(\"Textos:\", new_texts)\n",
    "print(\"Predições:\", predictions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo ficou ok, conseguiu prever a maioria dos clusters de acordo com as entidades nomeadas"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5784563,
     "sourceId": 9504313,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30806,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
