{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-10T21:26:56.487168Z",
     "iopub.status.busy": "2024-12-10T21:26:56.486490Z",
     "iopub.status.idle": "2024-12-10T21:26:57.519268Z",
     "shell.execute_reply": "2024-12-10T21:26:57.518394Z",
     "shell.execute_reply.started": "2024-12-10T21:26:56.487120Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dl-2024/dadosTextosCientificos.tsv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:45:19.556871Z",
     "iopub.status.busy": "2024-12-10T22:45:19.556010Z",
     "iopub.status.idle": "2024-12-10T22:45:45.254639Z",
     "shell.execute_reply": "2024-12-10T22:45:45.253702Z",
     "shell.execute_reply.started": "2024-12-10T22:45:19.556835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.8.0/pt_core_news_lg-3.8.0-py3-none-any.whl (568.2 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m568.2/568.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pt-core-news-lg\n",
      "Successfully installed pt-core-news-lg-3.8.0\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extrair carateres especiais, espa√ßos duplos, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:46:01.500050Z",
     "iopub.status.busy": "2024-12-10T22:46:01.499659Z",
     "iopub.status.idle": "2024-12-10T22:46:04.588500Z",
     "shell.execute_reply": "2024-12-10T22:46:04.587635Z",
     "shell.execute_reply.started": "2024-12-10T22:46:01.500016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando GPU: True\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# Configurar spaCy para usar GPU\n",
    "spacy.require_gpu()\n",
    "print(\"Usando GPU:\", spacy.prefer_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:46:07.901449Z",
     "iopub.status.busy": "2024-12-10T22:46:07.900943Z",
     "iopub.status.idle": "2024-12-10T22:46:07.964667Z",
     "shell.execute_reply": "2024-12-10T22:46:07.963817Z",
     "shell.execute_reply.started": "2024-12-10T22:46:07.901419Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T√≠tulo_P√∫blico</th>\n",
       "      <th>Descricao_p√∫blica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A√ß√∫car de frutas e aplica√ß√£o em bolos como sub...</td>\n",
       "      <td>O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desenvolver uma linha de farofas com castanhas...</td>\n",
       "      <td>O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desenvolvimento de cobertura l√≠quida para sorvete</td>\n",
       "      <td>O Brasil √© considerado um pa√≠s com a maior bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desenvolvimento de conserva de tomate cereja</td>\n",
       "      <td>O Brasil √© considerado o pa√≠s com maior biodiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desenvolvimento de massa aliment√≠cia enriqueci...</td>\n",
       "      <td>Nos √∫ltimos anos a comunidade cient√≠fica tem d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>Desenvolvimento de ativos biotecnol√≥gicos para...</td>\n",
       "      <td>O avan√ßo das tecnologias para estudos gen√¥mico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>SIMA MV POWER</td>\n",
       "      <td>Projeto de PD&amp;I para desenvolvimento de um sis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>Talhonameno √ìtimo Klabin</td>\n",
       "      <td>A Klabin S/A √© uma empresa brasileira, de car√°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>Tecnologia de Quantifica√ß√£o de Estoque de Carb...</td>\n",
       "      <td>Com a execu√ß√£o do presente projeto espera-se d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>¬ìDesenvolvimento de Plataforma Digital de Bioi...</td>\n",
       "      <td>Desenvolvimento de Plataforma Digital de Bioin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2725 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         T√≠tulo_P√∫blico  \\\n",
       "0     A√ß√∫car de frutas e aplica√ß√£o em bolos como sub...   \n",
       "1     Desenvolver uma linha de farofas com castanhas...   \n",
       "2     Desenvolvimento de cobertura l√≠quida para sorvete   \n",
       "3          Desenvolvimento de conserva de tomate cereja   \n",
       "4     Desenvolvimento de massa aliment√≠cia enriqueci...   \n",
       "...                                                 ...   \n",
       "2720  Desenvolvimento de ativos biotecnol√≥gicos para...   \n",
       "2721                                      SIMA MV POWER   \n",
       "2722                           Talhonameno √ìtimo Klabin   \n",
       "2723  Tecnologia de Quantifica√ß√£o de Estoque de Carb...   \n",
       "2724  ¬ìDesenvolvimento de Plataforma Digital de Bioi...   \n",
       "\n",
       "                                      Descricao_p√∫blica  \n",
       "0     O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...  \n",
       "1     O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...  \n",
       "2     O Brasil √© considerado um pa√≠s com a maior bio...  \n",
       "3     O Brasil √© considerado o pa√≠s com maior biodiv...  \n",
       "4     Nos √∫ltimos anos a comunidade cient√≠fica tem d...  \n",
       "...                                                 ...  \n",
       "2720  O avan√ßo das tecnologias para estudos gen√¥mico...  \n",
       "2721  Projeto de PD&I para desenvolvimento de um sis...  \n",
       "2722  A Klabin S/A √© uma empresa brasileira, de car√°...  \n",
       "2723  Com a execu√ß√£o do presente projeto espera-se d...  \n",
       "2724  Desenvolvimento de Plataforma Digital de Bioin...  \n",
       "\n",
       "[2725 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/dl-2024/dadosTextosCientificos.tsv',\n",
    "                   sep='\\t',\n",
    "                   engine='python',\n",
    "                   encoding='latin-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:46:35.705044Z",
     "iopub.status.busy": "2024-12-10T22:46:35.704682Z",
     "iopub.status.idle": "2024-12-10T22:46:38.638236Z",
     "shell.execute_reply": "2024-12-10T22:46:38.637500Z",
     "shell.execute_reply.started": "2024-12-10T22:46:35.705012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captando entidades de acordo com os temas: DUTOS, BIOATIVOS, BIOCOMBUST√çVEIS e COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:46:57.740199Z",
     "iopub.status.busy": "2024-12-10T22:46:57.739819Z",
     "iopub.status.idle": "2024-12-10T22:46:57.752177Z",
     "shell.execute_reply": "2024-12-10T22:46:57.751304Z",
     "shell.execute_reply.started": "2024-12-10T22:46:57.740164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_train = [\n",
    "    (\"Desenvolvimento de formula√ß√£o cosm√©tica veiculando sistema nanoestruturado lip√≠dico contendo pr√©-bioticos e p√≥s-bi√≥ticos\", {\"entities\": [(93, 105, \"BIOATIVOS\"), (108, 120, \"BIOATIVOS\")]}),\n",
    "    (\"intuito de incrementar nutricionalmente esses alimentos, agregando compostos bioativos e fibras\",{\"entities\": [(77, 86, \"BIOATIVOS\")]}),\n",
    "    (\"A empresa BIOATIVOSGROUP celebra em parceria com a Unidade Embrapii da UFABC\",{\"entities\": [(10, 24, \"BIOATIVOS\")]}),\n",
    "    (\"macrofungos associado ao biofertilizante Acrescent¬Æ capazes de controlar fungos\", {\"entities\": [(25, 40, \"BIOATIVOS\")]}),\n",
    "    (\"podem ser recuperados e transformados em coprodutos de valores nutricionais e bioativos\", {\"entities\": [(78, 87, \"BIOATIVOS\")]}),\n",
    "    (\"farinha de Ora-Pro-Nobis visando conserva√ß√£o de compostos bioativos\", {\"entities\": [(11, 24, \"BIOATIVOS\")]}),\n",
    "    (\"Extra√ß√£o e caracteriza√ß√£o de compostos bioativos\", {\"entities\": [(29, 48, \"BIOATIVOS\")]}),\n",
    "    (\"O objetivo do projeto √© desenvolver Metodologia de Inspe√ß√£o Baseada em Risco (IBR) para Sistemas de Dutos Flex√≠veis para a um planejamento do escopo de inspe√ß√£o\", {\"entities\": [(100, 115, \"DUTOS\")]}),\n",
    "    (\"Dispositivo Mitigador de Vibra√ß√£o Induzida por V√≥rtice para Dutos Submarinos\", {\"entities\": [(60, 76, \"DUTOS\")]}),\n",
    "    (\"Integridade e extens√£o de vida de dutos flex√≠veis\", {\"entities\": [(34, 49, \"DUTOS\")]}),\n",
    "    (\"sensores de ondas guiadas que possa mapear com precis√£o adequada a corros√£o em √°reas cr√≠ticas de dutos em opera√ß√£o\", {\"entities\": [(96, 101, \"DUTOS\")]}),\n",
    "    (\"Desenvolvimento de Metodologia para avalia√ß√£o em Fadiga das amraduras de tra√ß√£o em Risers Flex√≠veis\", {\"entities\": [(83, 99, \"DUTOS\")]}),\n",
    "    (\"mecanismos de degrada√ß√£o causados pelos fen√¥menos de fadiga e corros√£o fadiga em risers r√≠gidos e flex√≠veis\", {\"entities\": [(81, 107, \"DUTOS\")]}),\n",
    "    (\"Desenvolvimento de tubos bimet√°licos\", {\"entities\": [(19, 36, \"DUTOS\")]}),\n",
    "    (\"O objetivo geral do projeto √© quantificar o efeito do liner na resist√™ncia ao colapso de dutos submarinos mecanicamente cladeados\", {\"entities\": [(89, 105, \"DUTOS\")]}),\n",
    "    (\"Inspe√ß√£o de tubula√ß√µes com reparos em comp√≥sito com t√©cnica MWM-Array\", {\"entities\": [(12, 22, \"DUTOS\")]}),\n",
    "    (\"propriedades mec√¢nicas e integridade estrutural sob hidrogena√ß√£o em ligas de n√≠quel com altos teores\", {\"entities\": [(69, 84, \"DUTOS\")]}),\n",
    "    (\"associado ao ambiente corrosivo demanda dutos de elevada espessura\", {\"entities\": [(40, 45, \"DUTOS\")]}),\n",
    "    (\"vibra√ß√£o induzida por v√≥rtice que ser√° acoplado a dutos submarinos\", {\"entities\": [(50, 66, \"DUTOS\")]}),\n",
    "    (\"Desenvolver em escala de laborat√≥rio (TRL 3) o conceito para formula√ß√£o de biocombust√≠vel naval.\", {\"entities\": [(76, 90, \"BIOCOMBUST√çVEIS\")]}),\n",
    "    (\"gera√ß√£o de a√ß√∫cares avan√ßados e a produ√ß√£o de biocombust√≠veis\", {\"entities\": [(45, 60, \"BIOCOMBUST√çVEIS\")]}),\n",
    "    (\"Estrat√©gias Enzim√°ticas para Biocombustiveis avan√ßados\", {\"entities\": [(29, 44, \"BIOCOMBUST√çVEIS\")]}),\n",
    "    (\"Desenvolvimento do processo de produ√ß√£o de combust√≠veis sustent√°veis\", {\"entities\": [(43, 68, \"BIOCOMBUST√çVEIS\")]}),\n",
    "    (\"Desenvolvimento de me?todos para produc?a?o de bioquerosene\", {\"entities\": [(47, 59, \"BIOCOMBUST√çVEIS\")]}),\n",
    "    (\"Desenvolvimento de uma rota tecnol√≥gica para a produ√ß√£o de bio-√≥leo pirolenhoso\", {\"entities\": [(59, 67, \"BIOCOMBUST√çVEIS\")]}),\n",
    "    (\"Candidatos a f√°rmacos alvo dirigidos para o tratamento de infec√ß√µes virais por Coronav√≠rus\", {\"entities\": [(78, 89, \"COVID-19\")]}),\n",
    "    (\"Produ√ß√£o de prote√≠na S de SARS-COV-2 para desenvolvimento de testes de diagn√≥stico sorol√≥gico.\", {\"entities\": [(26, 36, \"COVID-19\")]}),\n",
    "    (\"Sistema de Triagem inteligente para diagn√≥stico da Covid 19\", {\"entities\": [(51, 59, \"COVID-19\")]}),\n",
    "    (\"Avaliar o potencial de difus√£o da COVID-19 pelo sistema de esgoto em centros urbanos\", {\"entities\": [(34, 42, \"COVID-19\")]}),\n",
    "    (\"Desenvolver um m√©todo padronizado e otimizado para detec√ß√£o do v√≠rus SARS-CoV2 em amostras de efluentes\", {\"entities\": [(68, 77, \"COVID-19\")]}),\n",
    "    (\"O aumento da temperatura corporal √© um dos indicadores para o diagn√≥stico de COVID19\", {\"entities\": [(77, 84, \"COVID-19\")]}),\n",
    "    (\"desenvolvendo um kit de teste quantitativo para monitoramento da COVID\", {\"entities\": [(65, 70, \"COVID-19\")]}),\n",
    "    (\"triagem e tratamento do covid 19 com uso de intelig√™ncia artificial\", {\"entities\": [(24, 32, \"COVID-19\")]}),\n",
    "    (\"Desenvolvimento de projeto de instrumenta√ß√£o e automa√ß√£o para sistema de higieniza√ß√£o e sanitiza√ß√£o de gases do Aerador-Filtro Anti-COVID\", {\"entities\": [(112, 137, \"COVID-19\")]})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento para reconhecer as entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:54:58.287701Z",
     "iopub.status.busy": "2024-12-10T22:54:58.287343Z",
     "iopub.status.idle": "2024-12-10T22:55:25.071238Z",
     "shell.execute_reply": "2024-12-10T22:55:25.070319Z",
     "shell.execute_reply.started": "2024-12-10T22:54:58.287671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-10 22:54:58,374] [INFO] Created vocabulary\n",
      "[2024-12-10 22:54:58,375] [INFO] Finished initializing nlp object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 Losses: {'ner': 340.02318942919374}\n",
      "Iteration 1 Losses: {'ner': 105.15050974596033}\n",
      "Iteration 2 Losses: {'ner': 56.061860582915585}\n",
      "Iteration 3 Losses: {'ner': 50.20962831809413}\n",
      "Iteration 4 Losses: {'ner': 45.41712229658356}\n",
      "Iteration 5 Losses: {'ner': 39.233577073310585}\n",
      "Iteration 6 Losses: {'ner': 39.850412801348895}\n",
      "Iteration 7 Losses: {'ner': 41.35663118632958}\n",
      "Iteration 8 Losses: {'ner': 47.70563071272673}\n",
      "Iteration 9 Losses: {'ner': 34.021011125986355}\n",
      "Iteration 10 Losses: {'ner': 29.573873683800528}\n",
      "Iteration 11 Losses: {'ner': 27.138512237150497}\n",
      "Iteration 12 Losses: {'ner': 23.42751169325361}\n",
      "Iteration 13 Losses: {'ner': 26.323659704035656}\n",
      "Iteration 14 Losses: {'ner': 14.816519659021232}\n",
      "Iteration 15 Losses: {'ner': 19.41776803421229}\n",
      "Iteration 16 Losses: {'ner': 11.670568890795323}\n",
      "Iteration 17 Losses: {'ner': 14.008300000391813}\n",
      "Iteration 18 Losses: {'ner': 12.711783663130415}\n",
      "Iteration 19 Losses: {'ner': 11.678893031066016}\n",
      "Iteration 20 Losses: {'ner': 10.567427317037366}\n",
      "Iteration 21 Losses: {'ner': 8.719005129850554}\n",
      "Iteration 22 Losses: {'ner': 11.366974690100955}\n",
      "Iteration 23 Losses: {'ner': 8.086432762822886}\n",
      "Iteration 24 Losses: {'ner': 7.515307469208864}\n",
      "Iteration 25 Losses: {'ner': 8.602369474944489}\n",
      "Iteration 26 Losses: {'ner': 9.080788861509278}\n",
      "Iteration 27 Losses: {'ner': 6.0235027546328785}\n",
      "Iteration 28 Losses: {'ner': 7.472565856800082}\n",
      "Iteration 29 Losses: {'ner': 7.9463902106304936}\n",
      "Iteration 30 Losses: {'ner': 7.006338299065311}\n",
      "Iteration 31 Losses: {'ner': 8.109711826390724}\n",
      "Iteration 32 Losses: {'ner': 3.2793729867128225}\n",
      "Iteration 33 Losses: {'ner': 6.7436864106048}\n",
      "Iteration 34 Losses: {'ner': 8.87096833644811}\n",
      "Iteration 35 Losses: {'ner': 4.26119703276998}\n",
      "Iteration 36 Losses: {'ner': 2.360647835443656}\n",
      "Iteration 37 Losses: {'ner': 3.4593763915483513}\n",
      "Iteration 38 Losses: {'ner': 2.028330100991832}\n",
      "Iteration 39 Losses: {'ner': 5.274568995724961}\n",
      "Iteration 40 Losses: {'ner': 1.5848794847598975}\n",
      "Iteration 41 Losses: {'ner': 3.3873980773686134}\n",
      "Iteration 42 Losses: {'ner': 4.385561039563745}\n",
      "Iteration 43 Losses: {'ner': 3.406097124464877}\n",
      "Iteration 44 Losses: {'ner': 4.8034418287026}\n",
      "Iteration 45 Losses: {'ner': 3.7572706330494747}\n",
      "Iteration 46 Losses: {'ner': 1.7799904146149617}\n",
      "Iteration 47 Losses: {'ner': 5.475974263055212}\n",
      "Iteration 48 Losses: {'ner': 1.9741752234386443}\n",
      "Iteration 49 Losses: {'ner': 4.059061041972956}\n",
      "Iteration 50 Losses: {'ner': 1.7426170009211754}\n",
      "Iteration 51 Losses: {'ner': 2.7546995057741666}\n",
      "Iteration 52 Losses: {'ner': 1.5961198342580472}\n",
      "Iteration 53 Losses: {'ner': 1.7163745538539932}\n",
      "Iteration 54 Losses: {'ner': 1.8295478929764095}\n",
      "Iteration 55 Losses: {'ner': 3.6485528421554956}\n",
      "Iteration 56 Losses: {'ner': 1.4524148595910722}\n",
      "Iteration 57 Losses: {'ner': 1.1594041035136768}\n",
      "Iteration 58 Losses: {'ner': 0.8137667334104528}\n",
      "Iteration 59 Losses: {'ner': 0.08817583796374882}\n",
      "Iteration 60 Losses: {'ner': 1.8924359361263932}\n",
      "Iteration 61 Losses: {'ner': 1.736469659278819}\n",
      "Iteration 62 Losses: {'ner': 2.2109687297704124}\n",
      "Iteration 63 Losses: {'ner': 0.34235754751968506}\n",
      "Iteration 64 Losses: {'ner': 1.5587535542837159}\n",
      "Iteration 65 Losses: {'ner': 1.9908329815221477}\n",
      "Iteration 66 Losses: {'ner': 0.17903663783482401}\n",
      "Iteration 67 Losses: {'ner': 0.06334968159780155}\n",
      "Iteration 68 Losses: {'ner': 0.9105209638957766}\n",
      "Iteration 69 Losses: {'ner': 0.2271659360076825}\n",
      "Iteration 70 Losses: {'ner': 2.163337192098158}\n",
      "Iteration 71 Losses: {'ner': 0.000830893031994215}\n",
      "Early stopping at iteration 71\n"
     ]
    }
   ],
   "source": [
    "#modelo spaCy vazio para portugu√™s\n",
    "nlp = spacy.blank(\"pt\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# r√≥tulos \n",
    "for _, annotations in data_train:\n",
    "    for ent in annotations[\"entities\"]:\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# Inicializar o otimizador\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "# N√∫mero m√°ximo de itera√ß√µes\n",
    "MAX_ITERATIONS = 100\n",
    "EARLY_STOPPING_THRESHOLD = 0.01  # Valor da loss para interrup√ß√£o antecipada\n",
    "\n",
    "# Treinamento\n",
    "for iteration in range(MAX_ITERATIONS):\n",
    "    random.shuffle(data_train)  # Embaralhar os dados\n",
    "    losses = {}\n",
    "\n",
    "    # Criar batches para treinamento\n",
    "    batches = minibatch(data_train, size=compounding(4.0, 32.0, 1.001))\n",
    "\n",
    "    for batch in batches:\n",
    "        examples = []\n",
    "        for text, annotations in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            try:\n",
    "                example = Example.from_dict(doc, annotations)  # Verificar desalinhamento\n",
    "                examples.append(example)\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping misaligned entities in: '{text}' - {e}\")\n",
    "\n",
    "        # Atualizar o modelo\n",
    "        nlp.update(examples, sgd=optimizer, drop=0.35, losses=losses)\n",
    "\n",
    "    print(f\"Iteration {iteration} Losses: {losses}\")\n",
    "\n",
    "    # Verificar interrup√ß√£o antecipada\n",
    "    if losses.get(\"ner\", 0) < EARLY_STOPPING_THRESHOLD:\n",
    "        print(f\"Early stopping at iteration {iteration}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T22:55:44.934900Z",
     "iopub.status.busy": "2024-12-10T22:55:44.934227Z",
     "iopub.status.idle": "2024-12-10T22:55:44.989670Z",
     "shell.execute_reply": "2024-12-10T22:55:44.988861Z",
     "shell.execute_reply.started": "2024-12-10T22:55:44.934868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo NER salvo.\n"
     ]
    }
   ],
   "source": [
    "# Salve o modelo\n",
    "nlp.to_disk(\"costum_ner\")\n",
    "print(\"Modelo NER salvo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando modelo NER personalizado para as entidades criadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T23:23:48.871338Z",
     "iopub.status.busy": "2024-12-10T23:23:48.870624Z",
     "iopub.status.idle": "2024-12-10T23:23:49.025828Z",
     "shell.execute_reply": "2024-12-10T23:23:49.024959Z",
     "shell.execute_reply.started": "2024-12-10T23:23:48.871303Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: O projeto tem como objetivo otimizar e escalonar a tecnologia de produ√ß√£o da prote√≠na S do coronav√≠rus SARS-COV-2, para que as empresas parceiras desenvolvam testes para diagn√≥stico sorol√≥gico de COVID-19, assim como estabelecer um painel de soros/plasmas positivos e negativos para COVID-19, que permita validar os testes diagn√≥stico e registr√°-los junto √† ANVISA\n",
      "Entidades: [('SARS-COV-2', 'COVID-19'), ('COVID-19', 'COVID-19'), ('COVID-19', 'COVID-19'), ('ANVISA', 'BIOATIVOS')]\n",
      "\n",
      "Texto: Desenvolvimento de me?todos para produc?a?o de bioquerosene/hidrocarbonetos verdes\n",
      "Entidades: [('bioquerosene', 'BIOCOMBUST√çVEIS')]\n",
      "\n",
      "Texto: Estabelecer uma metodologia consistente para avalia√ß√£o do fen√¥meno de fadiga desenvolvido nos arames que constituem as armaduras de tra√ß√£o de dutos flex√≠veis\n",
      "Entidades: [('dutos flex√≠veis', 'DUTOS')]\n",
      "\n",
      "Texto: Desenvolvimento de formula√ß√£o cosm√©tica veiculando sistema nanoestruturado lip√≠dico contendo pr√© e p√≥s-bi√≥ticos (vitaminas e √°cidos graxos de cadeia curta) a fim de promoverem o equil√≠brio da microbiota da pele\n",
      "Entidades: [('p√≥s-bi√≥ticos', 'BIOATIVOS')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregue o modelo treinado\n",
    "nlp = spacy.load(\"costum_ner\")\n",
    "\n",
    "# Exemplo de textos para extra√ß√£o de entidades\n",
    "texts = [\n",
    "    \"O projeto tem como objetivo otimizar e escalonar a tecnologia de produ√ß√£o da prote√≠na S do coronav√≠rus SARS-COV-2, para que as empresas parceiras desenvolvam testes para diagn√≥stico sorol√≥gico de COVID-19, assim como estabelecer um painel de soros/plasmas positivos e negativos para COVID-19, que permita validar os testes diagn√≥stico e registr√°-los junto √† ANVISA\",\n",
    "    \"Desenvolvimento de me?todos para produc?a?o de bioquerosene/hidrocarbonetos verdes\",\n",
    "    \"Estabelecer uma metodologia consistente para avalia√ß√£o do fen√¥meno de fadiga desenvolvido nos arames que constituem as armaduras de tra√ß√£o de dutos flex√≠veis\",\n",
    "    \"Desenvolvimento de formula√ß√£o cosm√©tica veiculando sistema nanoestruturado lip√≠dico contendo pr√© e p√≥s-bi√≥ticos (vitaminas e √°cidos graxos de cadeia curta) a fim de promoverem o equil√≠brio da microbiota da pele\"\n",
    "]\n",
    "\n",
    "# Extra√ß√£o de entidades\n",
    "entity_data = []\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    print(f\"Texto: {text}\\nEntidades: {entities}\\n\")\n",
    "    entity_data.append((text, entities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T23:25:18.214299Z",
     "iopub.status.busy": "2024-12-10T23:25:18.213323Z",
     "iopub.status.idle": "2024-12-10T23:25:18.231039Z",
     "shell.execute_reply": "2024-12-10T23:25:18.229893Z",
     "shell.execute_reply.started": "2024-12-10T23:25:18.214248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidade: compostos bioativos, R√≥tulo: BIOATIVOS\n",
      "Entidade: dutos submarinos, R√≥tulo: DUTOS\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Desenvolvimento de compostos bioativos e dutos submarinos.\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entidade: {ent.text}, R√≥tulo: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T23:34:27.890685Z",
     "iopub.status.busy": "2024-12-10T23:34:27.890330Z",
     "iopub.status.idle": "2024-12-10T23:34:27.895009Z",
     "shell.execute_reply": "2024-12-10T23:34:27.894049Z",
     "shell.execute_reply.started": "2024-12-10T23:34:27.890656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriquecendo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:05:46.802036Z",
     "iopub.status.busy": "2024-12-11T00:05:46.801299Z",
     "iopub.status.idle": "2024-12-11T00:06:05.493259Z",
     "shell.execute_reply": "2024-12-11T00:06:05.492538Z",
     "shell.execute_reply.started": "2024-12-11T00:05:46.801974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Carregar o modelo NER treinado\n",
    "nlp = spacy.load(\"costum_ner\")\n",
    "\n",
    "# Fun√ß√£o para enriquecer textos com entidades extra√≠das\n",
    "def enrich_with_entities(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):  # Tratar valores nulos e tipos inesperados\n",
    "        return text\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    return text + \" \" + \" \".join(entities)  # Concatenar texto original com entidades\n",
    "\n",
    "# Aplicar a fun√ß√£o para enriquecer os textos\n",
    "df[\"enriched_text\"] = df[\"Descricao_p√∫blica\"].apply(enrich_with_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:06:42.220897Z",
     "iopub.status.busy": "2024-12-11T00:06:42.220569Z",
     "iopub.status.idle": "2024-12-11T00:06:42.231782Z",
     "shell.execute_reply": "2024-12-11T00:06:42.230862Z",
     "shell.execute_reply.started": "2024-12-11T00:06:42.220870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T√≠tulo_P√∫blico</th>\n",
       "      <th>Descricao_p√∫blica</th>\n",
       "      <th>enriched_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A√ß√∫car de frutas e aplica√ß√£o em bolos como sub...</td>\n",
       "      <td>O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...</td>\n",
       "      <td>O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desenvolver uma linha de farofas com castanhas...</td>\n",
       "      <td>O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...</td>\n",
       "      <td>O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desenvolvimento de cobertura l√≠quida para sorvete</td>\n",
       "      <td>O Brasil √© considerado um pa√≠s com a maior bio...</td>\n",
       "      <td>O Brasil √© considerado um pa√≠s com a maior bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desenvolvimento de conserva de tomate cereja</td>\n",
       "      <td>O Brasil √© considerado o pa√≠s com maior biodiv...</td>\n",
       "      <td>O Brasil √© considerado o pa√≠s com maior biodiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desenvolvimento de massa aliment√≠cia enriqueci...</td>\n",
       "      <td>Nos √∫ltimos anos a comunidade cient√≠fica tem d...</td>\n",
       "      <td>Nos √∫ltimos anos a comunidade cient√≠fica tem d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>Desenvolvimento de ativos biotecnol√≥gicos para...</td>\n",
       "      <td>O avan√ßo das tecnologias para estudos gen√¥mico...</td>\n",
       "      <td>O avan√ßo das tecnologias para estudos gen√¥mico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>SIMA MV POWER</td>\n",
       "      <td>Projeto de PD&amp;I para desenvolvimento de um sis...</td>\n",
       "      <td>Projeto de PD&amp;I para desenvolvimento de um sis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>Talhonameno √ìtimo Klabin</td>\n",
       "      <td>A Klabin S/A √© uma empresa brasileira, de car√°...</td>\n",
       "      <td>A Klabin S/A √© uma empresa brasileira, de car√°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>Tecnologia de Quantifica√ß√£o de Estoque de Carb...</td>\n",
       "      <td>Com a execu√ß√£o do presente projeto espera-se d...</td>\n",
       "      <td>Com a execu√ß√£o do presente projeto espera-se d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>¬ìDesenvolvimento de Plataforma Digital de Bioi...</td>\n",
       "      <td>Desenvolvimento de Plataforma Digital de Bioin...</td>\n",
       "      <td>Desenvolvimento de Plataforma Digital de Bioin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2725 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         T√≠tulo_P√∫blico  \\\n",
       "0     A√ß√∫car de frutas e aplica√ß√£o em bolos como sub...   \n",
       "1     Desenvolver uma linha de farofas com castanhas...   \n",
       "2     Desenvolvimento de cobertura l√≠quida para sorvete   \n",
       "3          Desenvolvimento de conserva de tomate cereja   \n",
       "4     Desenvolvimento de massa aliment√≠cia enriqueci...   \n",
       "...                                                 ...   \n",
       "2720  Desenvolvimento de ativos biotecnol√≥gicos para...   \n",
       "2721                                      SIMA MV POWER   \n",
       "2722                           Talhonameno √ìtimo Klabin   \n",
       "2723  Tecnologia de Quantifica√ß√£o de Estoque de Carb...   \n",
       "2724  ¬ìDesenvolvimento de Plataforma Digital de Bioi...   \n",
       "\n",
       "                                      Descricao_p√∫blica  \\\n",
       "0     O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...   \n",
       "1     O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...   \n",
       "2     O Brasil √© considerado um pa√≠s com a maior bio...   \n",
       "3     O Brasil √© considerado o pa√≠s com maior biodiv...   \n",
       "4     Nos √∫ltimos anos a comunidade cient√≠fica tem d...   \n",
       "...                                                 ...   \n",
       "2720  O avan√ßo das tecnologias para estudos gen√¥mico...   \n",
       "2721  Projeto de PD&I para desenvolvimento de um sis...   \n",
       "2722  A Klabin S/A √© uma empresa brasileira, de car√°...   \n",
       "2723  Com a execu√ß√£o do presente projeto espera-se d...   \n",
       "2724  Desenvolvimento de Plataforma Digital de Bioin...   \n",
       "\n",
       "                                          enriched_text  \n",
       "0     O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...  \n",
       "1     O uso de inova√ß√µes tecnol√≥gicas auxilia as ind...  \n",
       "2     O Brasil √© considerado um pa√≠s com a maior bio...  \n",
       "3     O Brasil √© considerado o pa√≠s com maior biodiv...  \n",
       "4     Nos √∫ltimos anos a comunidade cient√≠fica tem d...  \n",
       "...                                                 ...  \n",
       "2720  O avan√ßo das tecnologias para estudos gen√¥mico...  \n",
       "2721  Projeto de PD&I para desenvolvimento de um sis...  \n",
       "2722  A Klabin S/A √© uma empresa brasileira, de car√°...  \n",
       "2723  Com a execu√ß√£o do presente projeto espera-se d...  \n",
       "2724  Desenvolvimento de Plataforma Digital de Bioin...  \n",
       "\n",
       "[2725 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando labels de acordo com os assuntos escolhidos e treinando classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:09:13.880865Z",
     "iopub.status.busy": "2024-12-11T00:09:13.880480Z",
     "iopub.status.idle": "2024-12-11T00:09:26.787479Z",
     "shell.execute_reply": "2024-12-11T00:09:26.786537Z",
     "shell.execute_reply.started": "2024-12-11T00:09:13.880835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696a7fe538e5411ca14fd3bada1c8121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26a32ab67bf40d1a7366dd5d465e92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_23/2740910689.py:93: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.302347</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.279306</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.277607</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas de avalia√ß√£o: {'eval_loss': 1.277606725692749, 'eval_accuracy': 0.5, 'eval_precision': 0.25, 'eval_recall': 0.5, 'eval_f1': 0.3333333333333333, 'eval_runtime': 0.0704, 'eval_samples_per_second': 28.408, 'eval_steps_per_second': 14.204, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import spacy\n",
    "\n",
    "# Configura√ß√µes gerais\n",
    "MODEL_NAME = \"neuralmind/bert-base-portuguese-cased\"  # Modelo BERTimbau\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 3\n",
    "MAX_LEN = 128\n",
    "\n",
    "# Verificar se GPU est√° dispon√≠vel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Carregar o modelo NER\n",
    "nlp = spacy.load(\"costum_ner\")\n",
    "\n",
    "# Fun√ß√£o para enriquecer textos com entidades extra√≠das\n",
    "def enrich_with_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    return text + \" \" + \" \".join(entities)\n",
    "\n",
    "# Dados de exemplo (substituir por dados reais)\n",
    "data = {\n",
    "    \"train\": [\n",
    "        {\"text\": \"Os dutos submarinos precisam de manuten√ß√£o urgente.\", \"label\": 0},\n",
    "        {\"text\": \"Biocombust√≠veis s√£o o futuro da energia sustent√°vel.\", \"label\": 1},\n",
    "        {\"text\": \"Os bioativos est√£o sendo usados em novas formula√ß√µes cosm√©ticas.\", \"label\": 2},\n",
    "        {\"text\": \"A pandemia de COVID-19 impactou a economia global.\", \"label\": 3},\n",
    "    ],\n",
    "    \"validation\": [\n",
    "        {\"text\": \"Dutos flex√≠veis s√£o utilizados em ambientes corrosivos.\", \"label\": 0},\n",
    "        {\"text\": \"A extra√ß√£o de bioativos ajuda na sa√∫de.\", \"label\": 2},\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Enriquecer os textos com entidades\n",
    "for split in data:\n",
    "    for item in data[split]:\n",
    "        item[\"text\"] = enrich_with_entities(item[\"text\"])\n",
    "\n",
    "# Convertendo os dados para DatasetDict\n",
    "train_dataset = Dataset.from_list(data[\"train\"])\n",
    "validation_dataset = Dataset.from_list(data[\"validation\"])\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"validation\": validation_dataset})\n",
    "\n",
    "# Carregando o tokenizer do modelo BERTimbau\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Fun√ß√£o para tokenizar os textos\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "# Tokenizando os datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Configurar colunas para treinamento\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Carregando o modelo pr√©-treinado com n√∫mero de classes definido\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=4)  # 4 classes\n",
    "model.to(device)  # Move o modelo explicitamente para a GPU\n",
    "\n",
    "# Configurar os argumentos de treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Fun√ß√£o para calcular m√©tricas de avalia√ß√£o\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Configurar o Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "trainer.train()\n",
    "\n",
    "# Avalia√ß√£o final\n",
    "metrics = trainer.evaluate()\n",
    "print(\"M√©tricas de avalia√ß√£o:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:09:36.802733Z",
     "iopub.status.busy": "2024-12-11T00:09:36.802368Z",
     "iopub.status.idle": "2024-12-11T00:09:36.882092Z",
     "shell.execute_reply": "2024-12-11T00:09:36.881032Z",
     "shell.execute_reply.started": "2024-12-11T00:09:36.802701Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textos: ['Os bioativos est√£o em alta na ind√∫stria farmac√™utica.', 'Dutos r√≠gidos s√£o amplamente utilizados em engenharia offshore.', 'A pandemia de COVID-19 levou ao desenvolvimento de vacinas.', 'Biocombust√≠veis reduzem a emiss√£o de carbono.']\n",
      "Predi√ß√µes: [2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predi√ß√£o em novos textos\n",
    "new_texts = [\n",
    "    \"Os bioativos est√£o em alta na ind√∫stria farmac√™utica.\",\n",
    "    \"Dutos r√≠gidos s√£o amplamente utilizados em engenharia offshore.\",\n",
    "    \"A pandemia de COVID-19 levou ao desenvolvimento de vacinas.\",\n",
    "    \"Biocombust√≠veis reduzem a emiss√£o de carbono.\"\n",
    "]\n",
    "\n",
    "# Enriquecer os novos textos com entidades\n",
    "new_texts_enriched = [enrich_with_entities(text) for text in new_texts]\n",
    "\n",
    "# Tokenizar os textos\n",
    "new_encodings = tokenizer(new_texts_enriched, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "new_encodings = {key: val.to(device) for key, val in new_encodings.items()}  # Move as entradas para GPU\n",
    "\n",
    "# Modelo em modo de avalia√ß√£o\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**new_encodings)\n",
    "    predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "print(\"Textos:\", new_texts)\n",
    "print(\"Predi√ß√µes:\", predictions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo ficou ok, conseguiu prever a maioria dos clusters de acordo com as entidades nomeadas"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5784563,
     "sourceId": 9504313,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30806,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
